{"cells":[{"cell_type":"markdown","metadata":{"id":"yk_NTN-tstLO"},"source":["El día de la semana con mayor número de Tweets de tu cuenta personal. Para ello deberás descargar de tu cuenta tu historial de Tweets, siguiendo las instrucciones siguientes: https://help.twitter.com/es/managing-your-account/how-to-download-your-twitter-archive \n","La descarga la habitarán pasadas 24 horas por motivos de seguridad.\n","Debes buscar el archivo llamado tweet.js, que tiene formato JSON."]},{"cell_type":"markdown","metadata":{"id":"AoWAePjQWzSe"},"source":["Instalar pyspark\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54719,"status":"ok","timestamp":1650063713894,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"Hv2nnAX6Ttis","outputId":"0f9e4954-a962-49fb-baed-1b0a1c2440aa"},"outputs":[],"source":["# !pip install pyspark"]},{"cell_type":"markdown","metadata":{"id":"JRhXVVw_XA2h"},"source":["**Creamos el SparkSession**\n","\n","Una SparkSession es el objeto principal o la base a partir de la cual cuelga toda la funcionalidad de Apache Spark. Es similar al SparkContext de los RDD, pero en este caso, para trabajar con SparkSQL, los DataFrame y DataSet \n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"S3AfHxbqXEAZ"},"outputs":[{"name":"stderr","output_type":"stream","text":["22/05/26 17:30:48 WARN Utils: Your hostname, Juanjos-Mac-mini.local resolves to a loopback address: 127.0.0.1; using 192.168.0.19 instead (on interface en0)\n","22/05/26 17:30:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n","Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n","Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","22/05/26 17:30:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"]}],"source":["from pyspark.sql import SparkSession\n","spark = SparkSession.builder\\\n",".master(\"local\")\\\n",".appName(\"Colab\")\\\n",".config('spark.ui.port', '4050')\\\n",".getOrCreate()"]},{"cell_type":"markdown","metadata":{"id":"ydH8cN0HXm9Z"},"source":["Leemos los datos del fichero Json, hay que recordar que los ficheros de datos JSON de twitter actualmente son multilinea"]},{"cell_type":"markdown","metadata":{"id":"k_qKGdIc4Saj"},"source":["Mostramos el esquema que tiene el dataframe obtenido de leer el archivo"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1p286qjm4bfV"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["root\n"," |-- tweet: struct (nullable = true)\n"," |    |-- created_at: string (nullable = true)\n"," |    |-- display_text_range: array (nullable = true)\n"," |    |    |-- element: string (containsNull = true)\n"," |    |-- entities: struct (nullable = true)\n"," |    |    |-- hashtags: array (nullable = true)\n"," |    |    |    |-- element: struct (containsNull = true)\n"," |    |    |    |    |-- indices: array (nullable = true)\n"," |    |    |    |    |    |-- element: string (containsNull = true)\n"," |    |    |    |    |-- text: string (nullable = true)\n"," |    |    |-- media: array (nullable = true)\n"," |    |    |    |-- element: struct (containsNull = true)\n"," |    |    |    |    |-- display_url: string (nullable = true)\n"," |    |    |    |    |-- expanded_url: string (nullable = true)\n"," |    |    |    |    |-- id: string (nullable = true)\n"," |    |    |    |    |-- id_str: string (nullable = true)\n"," |    |    |    |    |-- indices: array (nullable = true)\n"," |    |    |    |    |    |-- element: string (containsNull = true)\n"," |    |    |    |    |-- media_url: string (nullable = true)\n"," |    |    |    |    |-- media_url_https: string (nullable = true)\n"," |    |    |    |    |-- sizes: struct (nullable = true)\n"," |    |    |    |    |    |-- large: struct (nullable = true)\n"," |    |    |    |    |    |    |-- h: string (nullable = true)\n"," |    |    |    |    |    |    |-- resize: string (nullable = true)\n"," |    |    |    |    |    |    |-- w: string (nullable = true)\n"," |    |    |    |    |    |-- medium: struct (nullable = true)\n"," |    |    |    |    |    |    |-- h: string (nullable = true)\n"," |    |    |    |    |    |    |-- resize: string (nullable = true)\n"," |    |    |    |    |    |    |-- w: string (nullable = true)\n"," |    |    |    |    |    |-- small: struct (nullable = true)\n"," |    |    |    |    |    |    |-- h: string (nullable = true)\n"," |    |    |    |    |    |    |-- resize: string (nullable = true)\n"," |    |    |    |    |    |    |-- w: string (nullable = true)\n"," |    |    |    |    |    |-- thumb: struct (nullable = true)\n"," |    |    |    |    |    |    |-- h: string (nullable = true)\n"," |    |    |    |    |    |    |-- resize: string (nullable = true)\n"," |    |    |    |    |    |    |-- w: string (nullable = true)\n"," |    |    |    |    |-- type: string (nullable = true)\n"," |    |    |    |    |-- url: string (nullable = true)\n"," |    |    |-- symbols: array (nullable = true)\n"," |    |    |    |-- element: string (containsNull = true)\n"," |    |    |-- urls: array (nullable = true)\n"," |    |    |    |-- element: string (containsNull = true)\n"," |    |    |-- user_mentions: array (nullable = true)\n"," |    |    |    |-- element: string (containsNull = true)\n"," |    |-- extended_entities: struct (nullable = true)\n"," |    |    |-- media: array (nullable = true)\n"," |    |    |    |-- element: struct (containsNull = true)\n"," |    |    |    |    |-- display_url: string (nullable = true)\n"," |    |    |    |    |-- expanded_url: string (nullable = true)\n"," |    |    |    |    |-- id: string (nullable = true)\n"," |    |    |    |    |-- id_str: string (nullable = true)\n"," |    |    |    |    |-- indices: array (nullable = true)\n"," |    |    |    |    |    |-- element: string (containsNull = true)\n"," |    |    |    |    |-- media_url: string (nullable = true)\n"," |    |    |    |    |-- media_url_https: string (nullable = true)\n"," |    |    |    |    |-- sizes: struct (nullable = true)\n"," |    |    |    |    |    |-- large: struct (nullable = true)\n"," |    |    |    |    |    |    |-- h: string (nullable = true)\n"," |    |    |    |    |    |    |-- resize: string (nullable = true)\n"," |    |    |    |    |    |    |-- w: string (nullable = true)\n"," |    |    |    |    |    |-- medium: struct (nullable = true)\n"," |    |    |    |    |    |    |-- h: string (nullable = true)\n"," |    |    |    |    |    |    |-- resize: string (nullable = true)\n"," |    |    |    |    |    |    |-- w: string (nullable = true)\n"," |    |    |    |    |    |-- small: struct (nullable = true)\n"," |    |    |    |    |    |    |-- h: string (nullable = true)\n"," |    |    |    |    |    |    |-- resize: string (nullable = true)\n"," |    |    |    |    |    |    |-- w: string (nullable = true)\n"," |    |    |    |    |    |-- thumb: struct (nullable = true)\n"," |    |    |    |    |    |    |-- h: string (nullable = true)\n"," |    |    |    |    |    |    |-- resize: string (nullable = true)\n"," |    |    |    |    |    |    |-- w: string (nullable = true)\n"," |    |    |    |    |-- type: string (nullable = true)\n"," |    |    |    |    |-- url: string (nullable = true)\n"," |    |-- favorite_count: string (nullable = true)\n"," |    |-- favorited: boolean (nullable = true)\n"," |    |-- full_text: string (nullable = true)\n"," |    |-- id: string (nullable = true)\n"," |    |-- id_str: string (nullable = true)\n"," |    |-- lang: string (nullable = true)\n"," |    |-- possibly_sensitive: boolean (nullable = true)\n"," |    |-- retweet_count: string (nullable = true)\n"," |    |-- retweeted: boolean (nullable = true)\n"," |    |-- source: string (nullable = true)\n"," |    |-- truncated: boolean (nullable = true)\n","\n"]}],"source":["data = spark.read.option(\"multiline\", \"true\").json(\"ejemploTweets.js\")\n","\n","data.printSchema()"]},{"cell_type":"markdown","metadata":{"id":"h2_gi_w34K7e"},"source":["Tomamos dos campos, uno de ellos en el que aparece la fecha de creación del Tweet y otro por ejemplo el que presenta el texto completo. 'created_at' 'full_text'"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"sEmp2gi2aXvO"},"outputs":[],"source":["data = data.select(\"tweet.created_at\", \"tweet.full_text\")"]},{"cell_type":"markdown","metadata":{"id":"tWmIn4V74ukA"},"source":["Para trabajar mostramos la colección completa del dataset por filas (Row)  \n"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"kLxh70ow4tK1"},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]},{"data":{"text/plain":["[Row(created_at='Sun Nov 25 15:54:43 +0000 2012', full_text='Tweet 1'),\n"," Row(created_at='Mon Nov 05 23:58:38 +0000 2012', full_text='Tweet 2'),\n"," Row(created_at='Sat Oct 06 15:12:10 +0000 2012', full_text='Tweet 3'),\n"," Row(created_at='Wed Aug 29 15:27:42 +0000 2012', full_text='Tweet 4'),\n"," Row(created_at='Fri Aug 03 16:18:13 +0000 2012', full_text='Tweet 5'),\n"," Row(created_at='Sun Jul 22 21:31:54 +0000 2012', full_text='Tweet 6'),\n"," Row(created_at='Sat Jul 21 21:36:20 +0000 2012', full_text='Tweet 7'),\n"," Row(created_at='Sun Jul 15 15:36:26 +0000 2012', full_text='Tweet 8'),\n"," Row(created_at='Sun Jul 08 21:24:32 +0000 2012', full_text='Tweet 9'),\n"," Row(created_at='Mon Jul 02 07:11:46 +0000 2012', full_text='Tweet 10'),\n"," Row(created_at='Sun Jun 17 20:02:56 +0000 2012', full_text='Tweet 11'),\n"," Row(created_at='Wed Jun 06 22:02:21 +0000 2012', full_text='Tweet 12'),\n"," Row(created_at='Sun Jun 03 13:25:18 +0000 2012', full_text='Tweet 13'),\n"," Row(created_at='Sun Apr 29 16:11:30 +0000 2012', full_text='Tweet 14'),\n"," Row(created_at='Sat Apr 28 13:42:36 +0000 2012', full_text='Tweet 15'),\n"," Row(created_at='Sat Apr 28 08:19:44 +0000 2012', full_text='Tweet 16'),\n"," Row(created_at='Sat Mar 17 13:40:15 +0000 2012', full_text='Tweet 17'),\n"," Row(created_at='Fri Mar 16 21:46:15 +0000 2012', full_text='Tweet 18'),\n"," Row(created_at='Tue May 01 17:28:01 +0000 2018', full_text='Tweet 19'),\n"," Row(created_at='Sat Jul 22 21:19:02 +0000 2017', full_text='Tweet 20'),\n"," Row(created_at='Sat Jul 22 17:53:46 +0000 2017', full_text='Tweet 21'),\n"," Row(created_at='Sat Jul 22 08:04:28 +0000 2017', full_text='Tweet 22')]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["data.collect()"]},{"cell_type":"markdown","metadata":{"id":"INVbw7Ei453K"},"source":["Hacemos una prueba mostrando de cada fila sólamente el primer campo con la fecha de creación del Tweet y los tres primeros caracteres correspondientes al día de la semana."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1650064736159,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"7rTZxcS_cuEM"},"outputs":[{"name":"stdout","output_type":"stream","text":["Nov 25 15:54:43 - Sun\n","Nov 05 23:58:38 - Mon\n","Oct 06 15:12:10 - Sat\n","Aug 29 15:27:42 - Wed\n","Aug 03 16:18:13 - Fri\n","Jul 22 21:31:54 - Sun\n","Jul 21 21:36:20 - Sat\n","Jul 15 15:36:26 - Sun\n","Jul 08 21:24:32 - Sun\n","Jul 02 07:11:46 - Mon\n","Jun 17 20:02:56 - Sun\n","Jun 06 22:02:21 - Wed\n","Jun 03 13:25:18 - Sun\n","Apr 29 16:11:30 - Sun\n","Apr 28 13:42:36 - Sat\n","Apr 28 08:19:44 - Sat\n","Mar 17 13:40:15 - Sat\n","Mar 16 21:46:15 - Fri\n","May 01 17:28:01 - Tue\n","Jul 22 21:19:02 - Sat\n","Jul 22 17:53:46 - Sat\n","Jul 22 08:04:28 - Sat\n"]}],"source":["tweets = data.collect()\n","\n","for row in tweets:\n","\n","    print(\"{0} - {1}\".format(\" \".join(row[\"created_at\"].split(\" \")[1:4]), row[\"created_at\"].split(\" \")[0]))"]},{"cell_type":"markdown","metadata":{"id":"ilZblAdK5Mgb"},"source":["Generamos un nuevo dataframe con los tweets reducidos (en este caso vamos a tomar solo los tres primeros caracteres de la primera columna con la fecha de creación, de forma similar a como lo hicimos en el bloque anterior, y el segundo campo sin modificaciones)"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"ygV_kWQS6uzX"},"outputs":[],"source":["from pyspark.sql.functions import *\n","\n","data = []\n","\n","for row in tweets:\n","\n","    data = data.append([\" \".join(row[\"created_at\"].split(\" \")[1:4]), row[\"full_text\"]])\n","\n","reduced_tweets = \n"]},{"cell_type":"markdown","metadata":{"id":"Lw2IQ8BO514l"},"source":["Creamos un nuevo dataframe a partir del anterior renombrando la primera columna por \"dias_semana\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XYRQhqL7__xH"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"WEpi0nIR56Qz"},"source":["Realizamos el conteo total de tweets que hemos realizado"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":221,"status":"ok","timestamp":1650064779745,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"vHlXqCg5IsVB"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"rGDavj_Q5_Io"},"source":["Obtenemos un nuevo dataframe con los tweets agrupados por día de la semana y ordenados de forma descendente"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":231,"status":"ok","timestamp":1650064789173,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"bfPc3gYI88X4"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"TsNWxUoW6NZX"},"source":["Tomamos el primer elemento del dataframe ordenado y lo mostramos"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5446,"status":"ok","timestamp":1650064803058,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"VYH_7rh6rntl"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"qhR-dPXdsqLN"},"source":["Mostrar un dataframe con todos los datos, que muestre un array de hashtags, el texto completo y el número de likes que tiene cada uno. Que se muestre en vertical y sin truncar el texto."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":219,"status":"ok","timestamp":1650064806913,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"II56YrPi6XKw"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MnDRgO9uw81O"},"source":["Obtener a partir del dataframe anterior los tweets ordenados de forma descendente de los que tienen más *likes* a los que menos, mostrando solo el texto del tweet y el número de likes de forma vertical y sin truncar el texto"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":301,"status":"ok","timestamp":1650064815276,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"w9p8TWP7wZDo"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"TJMkfuXk4lNQ"},"source":["Obtener el número máximo de likes que ha obtenido un tweet"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":239,"status":"ok","timestamp":1650064825821,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"IcLQcY1ByAXq"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"MtLpxVAs5vWS"},"source":["Obtener el total de likes obteidos por el usuario"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":211,"status":"ok","timestamp":1650064832230,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"2S6Q4E9H4t1g"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5Oc3D6pe546-"},"source":["Filtrar y obtener sólo los tweets que tengan el máximo de likes, mostrando el texto completo y el número de likes, y comprobar que coincide con el valor obtenido en los bloques anteriores."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":257,"status":"ok","timestamp":1650064880278,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"RAEofYCDyogU"},"outputs":[],"source":["from pyspark.sql.functions import *\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"No6KJu8RgHC7"},"source":["Pasar el Dataframe a un RDD, y mostrar los datos eliminando de la cadena desde la posición 15 hasta la penúltima"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":240,"status":"ok","timestamp":1650064889773,"user":{"displayName":"David Martin","userId":"13982407448269417970"},"user_tz":-120},"id":"gR55eHbp6dqM"},"outputs":[],"source":["from pyspark.context import SparkContext\n","\n","\n","\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Tarea 3.2-Ejercicio DataFrame.ipynb","provenance":[{"file_id":"1F2Ruv9o2t66Rv3VBzW8NgHq_wOcjiu3l","timestamp":1650063597049}]},"interpreter":{"hash":"f2ec7104d0b563fded5ffd12705406214d4ed020b43c1b3546134c42f3250eb5"},"kernelspec":{"display_name":"Python 3.9.10 ('big-data-programacion-UpxatWFW-py3.9')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}
